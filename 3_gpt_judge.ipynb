{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ee8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5827e0",
   "metadata": {},
   "source": [
    "### Load Evaluation Question (Rubrics) and Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rubrics for general part of the dataset\n",
    "FILE_PATH = os.path.join('eval_rubric', 'rubrics_general.xlsx')\n",
    "df_rubrics_general = pd.read_excel(FILE_PATH)\n",
    "df_rubrics_general.head()\n",
    "\n",
    "# dictionary to store rubrics for each specific harms\n",
    "rubrics_general = {}\n",
    "current_category = None\n",
    "\n",
    "# iterate through the rows\n",
    "for _, row in df_rubrics_general.iterrows():\n",
    "    if pd.notna(row[\"Category\"]):\n",
    "        current_category = row[\"Category\"]\n",
    "        rubrics_general[current_category] = []\n",
    "    rubrics_general[current_category].append(f\"{row['Question']}\")\n",
    "    \n",
    "# rubrics_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rubrics for Indonesian-specific part of the dataset\n",
    "FILE_PATH = os.path.join('eval_rubric', 'rubrics_indonesia.xlsx')\n",
    "df_rubrics_indonesian = pd.read_excel(FILE_PATH)\n",
    "df_rubrics_indonesian.head()\n",
    "\n",
    "# dictionary to store rubrics for each specific harms\n",
    "rubrics_indonesian = {}\n",
    "current_category = None\n",
    "\n",
    "# iterate through the rows\n",
    "for _, row in df_rubrics_indonesian.iterrows():\n",
    "    if pd.notna(row[\"Category\"]):\n",
    "        current_category = row[\"Category\"]\n",
    "        rubrics_indonesian[current_category] = []\n",
    "    rubrics_indonesian[current_category].append(f\"{row['Question']}\")\n",
    "\n",
    "# rubrics_indonesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a52f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the evaluation template\n",
    "template = \"\"\n",
    "FILE_PATH = os.path.join('prompt_templates', 'eval_template.txt')\n",
    "with open(FILE_PATH, \"r\") as file:\n",
    "    template = file.read()\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a32e4b",
   "metadata": {},
   "source": [
    "### Judge Responses With GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b9e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key securely\n",
    "client = OpenAI(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "# set input and output dir\n",
    "INPUT_DIR = '1_responses'\n",
    "OUTPUT_DIR = '2_responses_judged'\n",
    "\n",
    "# Listing all .xlsx files to process\n",
    "files = [f for f in os.listdir(INPUT_DIR) if f.endswith('.xlsx')]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_requests = dict()\n",
    "\n",
    "# loop through all files\n",
    "for file in files:\n",
    "    requests = []\n",
    "    file_path = os.path.join(INPUT_DIR, file)\n",
    "    \n",
    "    print(f\"Processing file: {file}\")\n",
    "\n",
    "    # load the excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # loop through all rows\n",
    "    for index, row in df.iterrows():\n",
    "        # assuming the column 4 is the prompt and column 5 is the response\n",
    "        question = str(row[4])\n",
    "        response = str(row[5])\n",
    "\n",
    "        # for region-specific sensitivity, the rubrics are for each specific harm\n",
    "        # for general sensitivity, the rubrics are for each risk area\n",
    "        if row['risk_area'] == 'Region-specific Sensitivity':\n",
    "            category = row['specific_harms']\n",
    "            rubrics = rubrics_indonesian[category]\n",
    "        else:\n",
    "            category = row['risk_area']\n",
    "            rubrics = rubrics_general[category]\n",
    "\n",
    "        for i, rubric in enumerate(rubrics, start=1):\n",
    "            column_name = f\"Rubric {i}\"\n",
    "            column_name_q = f\"Rubric {i} question\"\n",
    "            filled_template = template \n",
    "            filled_template = filled_template.replace(\"[Q_EVALUASI]\", rubric) \\\n",
    "                                    .replace(\"[PERTANYAAN]\", question) \\\n",
    "                                    .replace(\"[JAWABAN]\", response)\n",
    "            message = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant. Answer questions according to the language used by the user.\"},\n",
    "                {\"role\": \"user\", \"content\": filled_template}\n",
    "            ]\n",
    "\n",
    "            # encode rubric number 'i' for prompt number 'index' to custom_id\n",
    "            # will be useful later\n",
    "            requests.append({\n",
    "                \"custom_id\": f'{index}_{i}',\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"messages\": message,\n",
    "                }\n",
    "            })\n",
    "    file_to_requests[file] = requests\n",
    "file_to_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write temporary jsonl for batch API request\n",
    "requests_dir = 'temp_jsonl'\n",
    "file_to_batches = dict()\n",
    "\n",
    "# send batch request for each .xlsx file\n",
    "for file in file_to_requests.keys():\n",
    "    filename_jsonl = file[:-5] + \".jsonl\" # replace file format .xlsx (last five characters) to .jsonl\n",
    "    path_jsonl = os.path.join(requests_dir, filename_jsonl)\n",
    "    with open(path_jsonl, \"w\") as f:\n",
    "        for req in file_to_requests[file]:\n",
    "            f.write(json.dumps(req) + \"\\n\")\n",
    "\n",
    "    # upload file for batch processing\n",
    "    uploaded_file = client.files.create(\n",
    "        file=open(path_jsonl, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    # send batch request\n",
    "    batch = client.batches.create(\n",
    "        input_file_id=uploaded_file.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Using GPT-4o as a judge for: {file}\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # keep track of each file's corresponding batch id\n",
    "    file_to_batches[file] = batch.id\n",
    "\n",
    "file_to_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all batch status\n",
    "for filename in file_to_batches.keys():\n",
    "    batch_status = client.batches.retrieve(file_to_batches[filename])\n",
    "    print(f\"‚è≥ Status {filename}: {batch_status.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: only run this part after all batch processing are completed\n",
    "\n",
    "# process each file\n",
    "for filename in file_to_batches.keys():\n",
    "    batch_status = client.batches.retrieve(file_to_batches[filename])\n",
    "    output_file_id = batch_status.output_file_id\n",
    "    file_response = client.files.content(output_file_id)\n",
    "    results = [json.loads(line) for line in file_response.text.strip().split(\"\\n\")]\n",
    "    file_path = os.path.join(INPUT_DIR, filename)\n",
    "\n",
    "    # add more if use more rubrics\n",
    "    df_result = pd.read_excel(file_path)\n",
    "    df_result[\"Rubric 1\"] = None\n",
    "    df_result[\"Rubric 2\"] = None\n",
    "    df_result[\"Rubric 3\"] = None\n",
    "\n",
    "    for result in results:\n",
    "        prompt_number, rubric_number = result['custom_id'].split(\"_\") # decode rubric number and prompt number\n",
    "        content = result['response']['body']['choices'][0]['message']['content']\n",
    "        df_result.iloc[int(prompt_number), df_result.columns.get_loc(f\"Rubric {rubric_number}\")] = content\n",
    "    \n",
    "    # create output file\n",
    "    output_file_name = f\"result_{filename}\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, output_file_name)\n",
    "    df_result.to_excel(output_path, index=False)\n",
    "    print(f\"Finished processing {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
