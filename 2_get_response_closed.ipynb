{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90747d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "import anthropic\n",
    "import os\n",
    "from anthropic.types.message_create_params import MessageCreateParamsNonStreaming\n",
    "from anthropic.types.messages.batch_create_params import Request\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158626b",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0efc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = 'dataset'\n",
    "EVAL1_PATH = os.path.join(FOLDER_NAME, 'IndoSafety-Eval-1.xlsx')\n",
    "EVAL2_PATH = os.path.join(FOLDER_NAME, 'IndoSafety-Eval-2.xlsx')\n",
    "\n",
    "df_eval_1 = pd.read_excel(EVAL1_PATH)\n",
    "df_eval_2 = pd.read_excel(EVAL2_PATH)\n",
    "\n",
    "langs = [\n",
    "    'indonesian-formal',\n",
    "    'colloquial',\n",
    "    'minangkabau',\n",
    "    'java',\n",
    "    'sunda'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeff9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set output folder path\n",
    "OUTPUT_FOLDER_PATH = '1_responses'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1077c39",
   "metadata": {},
   "source": [
    "## Collect Responses from GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18018936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key securely\n",
    "client = OpenAI(api_key=\"YOUR_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e9213",
   "metadata": {},
   "source": [
    "### IndoSafety-Eval-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e76b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = []\n",
    "\n",
    "for i, row in df_eval_1.iterrows():\n",
    "    user_input = str(row['prompt'])\n",
    "    custom_id = row['id']\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant. Answer questions according to the language used by the user.\"},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    requests.append({\n",
    "        \"custom_id\": f'{custom_id}',\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"messages\": message\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Save to JSONL\n",
    "TEMP_PATH = os.path.join('temp_jsonl', \"gpt-4o_generate_eval1_responses.jsonl\")\n",
    "with open(TEMP_PATH, \"w\") as f:\n",
    "    for req in requests:\n",
    "        f.write(json.dumps(req) + \"\\n\")\n",
    "\n",
    "# Upload the request file\n",
    "uploaded_file = client.files.create(\n",
    "    file=open(TEMP_PATH, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "# Submit the batch using the uploaded file ID\n",
    "batch = client.batches.create(\n",
    "    input_file_id=uploaded_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"Collect responses from GPT-4o (Eval-1)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ Batch submitted. ID:\", batch.id)\n",
    "batch_id = batch.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47daade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check batch status\n",
    "batch_status = client.batches.retrieve(batch_id)\n",
    "print(f\"⏳ Status: {batch_status.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect responses\n",
    "output_file_id = batch_status.output_file_id\n",
    "file_response = client.files.content(output_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract result into dictionary\n",
    "results = [json.loads(line) for line in file_response.text.strip().split(\"\\n\")]\n",
    "post_results = {}\n",
    "for result in results:\n",
    "    custom_id = int(result['custom_id'])\n",
    "    content = result['response']['body']['choices'][0]['message']['content']\n",
    "    post_results[custom_id] = content\n",
    "keys = post_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8595ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate output file\n",
    "responses = []\n",
    "for key in keys:\n",
    "    responses.append(post_results[key])\n",
    "\n",
    "output_filename = f'result_eval1_gpt-4o.xlsx'\n",
    "output_path = os.path.join(OUTPUT_FOLDER_PATH, output_filename)\n",
    "df_new = df_eval_1[['id','risk_area','types_of_harm','specific_harms', 'prompt']].copy()\n",
    "df_new[f'eval1_gpt/gpt-4o_response'] = responses\n",
    "df_new.to_excel(output_path, index=False, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2514a9",
   "metadata": {},
   "source": [
    "### IndoSafety-Eval-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = []\n",
    "count = 0\n",
    "\n",
    "# Generate requests for each row and language\n",
    "for lang in langs:\n",
    "    for i, row in df_eval_2.iterrows():\n",
    "        user_input = str(row[lang])\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant. Answer questions according to the language used by the user.\"},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "        requests.append({\n",
    "            \"custom_id\": f'{count}',\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o\",\n",
    "                \"messages\": message\n",
    "            }\n",
    "        })\n",
    "        count += 1\n",
    "\n",
    "# Save to JSONL\n",
    "TEMP_PATH = os.path.join('temp_jsonl', \"gpt-4o_generate_eval2_responses.jsonl\")\n",
    "with open(TEMP_PATH, \"w\") as f:\n",
    "    for req in requests:\n",
    "        f.write(json.dumps(req) + \"\\n\")\n",
    "\n",
    "# Upload the request file\n",
    "uploaded_file = client.files.create(\n",
    "    file=open(TEMP_PATH, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "# Submit the batch using the uploaded file ID\n",
    "batch = client.batches.create(\n",
    "    input_file_id=uploaded_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"Collect responses from GPT-4o  (Eval-2)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ Batch submitted. ID:\", batch.id)\n",
    "batch_id = batch.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f56a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check batch status\n",
    "batch_status = client.batches.retrieve(batch_id)\n",
    "print(f\"⏳ Status: {batch_status.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff39abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect responses\n",
    "output_file_id = batch_status.output_file_id\n",
    "file_response = client.files.content(output_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48719add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract result into dictionary\n",
    "results = [json.loads(line) for line in file_response.text.strip().split(\"\\n\")]\n",
    "post_results = {}\n",
    "for result in results:\n",
    "    custom_id = int(result['custom_id'])\n",
    "    content = result['response']['body']['choices'][0]['message']['content']\n",
    "    post_results[custom_id] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22806156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate output file\n",
    "counter = 0\n",
    "lang_idx = 0\n",
    "responses = []\n",
    "while lang_idx < 5: # terminate if all five language variants have been processed\n",
    "    responses.append(post_results[counter])\n",
    "    counter += 1\n",
    "    if counter==len(df_eval_2):\n",
    "        lang = langs[lang_idx]\n",
    "        output_filename = f'result_{lang}_gpt-4o.xlsx'\n",
    "        output_path = os.path.join(OUTPUT_FOLDER_PATH, output_filename)\n",
    "        df_new = df_eval_2[['id','risk_area','types_of_harm','specific_harms',lang]].copy()\n",
    "        df_new[f'{lang}_gpt/gpt-4o_response'] = responses\n",
    "        df_new.to_excel(output_path, index=False, engine=\"openpyxl\")\n",
    "        counter = 0\n",
    "        lang_idx += 1\n",
    "        responses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2080d34b",
   "metadata": {},
   "source": [
    "## Collect Responses from Claude 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36213835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key securely\n",
    "client = anthropic.Anthropic(api_key='YOUR_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f661d2",
   "metadata": {},
   "source": [
    "### IndoSafety-Eval-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = []\n",
    "count = 0\n",
    "\n",
    "for i, row in df_eval_1.iterrows():\n",
    "    user_input = str(row['prompt'])\n",
    "    message = [{\"role\": \"user\", \"content\": user_input}]\n",
    "    request = Request(\n",
    "        custom_id=str(count),\n",
    "        params=MessageCreateParamsNonStreaming(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=2048,\n",
    "            messages=message\n",
    "        )\n",
    "    )\n",
    "    requests.append(request)\n",
    "    count += 1\n",
    "\n",
    "message_batch = client.messages.batches.create(requests=requests)\n",
    "batch_id = message_batch.id\n",
    "print(message_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0610a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check batch status\n",
    "message_batch = client.messages.batches.retrieve(batch_id)\n",
    "print(f\"Batch {batch_id} processing status is {message_batch.processing_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate output file\n",
    "responses = []\n",
    "for result in client.messages.batches.results(batch_id):\n",
    "    responses.append(result.result.message.content[0].text)\n",
    "output_filename = f'result_eval1_claude-3-haiku.xlsx'\n",
    "output_path = os.path.join(OUTPUT_FOLDER_PATH, output_filename)\n",
    "df_new = df_eval_1[['id','risk_area','types_of_harm','specific_harms','prompt']].copy()\n",
    "df_new[f'eval1_anthropic/claude-3-haiku_response'] = responses\n",
    "df_new.to_excel(output_path, index=False, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2274c1c9",
   "metadata": {},
   "source": [
    "### IndoSafety-Eval-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2588e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = []\n",
    "\n",
    "# Generate requests for each row and language\n",
    "for lang in langs:\n",
    "    for i, row in df_eval_2.iterrows():\n",
    "        user_input = str(row[lang])\n",
    "        message = [{\"role\": \"user\", \"content\": user_input}]\n",
    "        unique_id = str(uuid.uuid4())\n",
    "        request = Request(\n",
    "            custom_id=unique_id,\n",
    "            params=MessageCreateParamsNonStreaming(\n",
    "                model=\"claude-3-haiku-20240307\",\n",
    "                max_tokens=2048,\n",
    "                messages=message\n",
    "            )\n",
    "        )\n",
    "        requests.append(request)\n",
    "\n",
    "message_batch = client.messages.batches.create(requests=requests)\n",
    "batch_id = message_batch.id\n",
    "print(message_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffbd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check batch status\n",
    "message_batch = client.messages.batches.retrieve(batch_id)\n",
    "print(f\"Batch {batch_id} processing status is {message_batch.processing_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate output file\n",
    "counter = 0\n",
    "lang_idx = 0\n",
    "responses = []\n",
    "for result in client.messages.batches.results(batch_id):\n",
    "    counter += 1\n",
    "    responses.append(result.result.message.content[0].text)\n",
    "    if counter==500:\n",
    "        lang = langs[lang_idx]\n",
    "        output_filename = f'result_{lang}_claude-3-haiku.xlsx'\n",
    "        output_path = os.path.join(OUTPUT_FOLDER_PATH, output_filename)\n",
    "        df_new = df_eval_2[['id','risk_area','types_of_harm','specific_harms',lang]].copy()\n",
    "        df_new[f'{lang}_anthropic/claude-3-haiku_response'] = responses\n",
    "        df_new.to_excel(output_path, index=False, engine=\"openpyxl\")\n",
    "        counter = 0\n",
    "        lang_idx += 1\n",
    "        responses = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
